 Outlier Engineering


An outlier is a data point which is significantly different from the remaining data. 
“An outlier is an observation which deviates so much from the other observations as to 
arouse suspicions that it was generated by a different mechanism.” [D. Hawkins. 
Identification of Outliers, Chapman and Hall , 1980].

Statistics such as the mean and variance are very susceptible to outliers. In addition, *
*some Machine Learning models are sensitive to outliers** which may decrease their performance. 
Thus, depending on which algorithm we wish to train, we often remove outliers from our variables.

We discussed in section 3 of this course how to identify outliers. In this section, 
we we discuss how we can process them to train our machine learning models.


 How can we pre-process outliers?

- Trimming: remove the outliers from our dataset
- Treat outliers as missing data, and proceed with any missing data imputation technique
- Discrestisation: outliers are placed in border bins together with higher or lower values 
of the distribution- Censoring: capping the variable distribution at a max and / or minimum value

**Censoring** is also known as:

- top and bottom coding
- winsorization
- capping


 Censoring or Capping.

**Censoring**, or **capping**, means capping the maximum and /or minimum of a distribution at an 
arbitrary value. On other words, values bigger or smaller than the arbitrarily determined ones 
are **censored**.

Capping can be done at both tails, or just one of the tails, depending on the variable and the user.

Check [pydata](https://www.youtube.com/watch?v=KHGGlozsRtA), by Soledad Galli, for an example 
of capping used in a finance company.

The numbers at which to cap the distribution can be determined:

- arbitrarily
- using the inter-quantal range proximity rule
- using the gaussian approximation
- using quantiles


 Advantages

- does not remove data

 Limitations

- distorts the distributions of the variables
- distorts the relationships among variables


 In this Demo

We will see how to perform capping with the gaussian approximation

 Important

When doing capping, we tend to cap values both in train and test set. It is important to 
remember that the capping values MUST be derived from the train set. And then use those same 
values to cap the variables in the test set

I will not do that in this demo, but please keep that in mind when setting up your pipelines
